{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv', sep='\\t')\n",
    "test = pd.read_csv('test.csv', sep='\\t')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "x_train = train[\"text\"]\n",
    "y_train = train[\"label\"]\n",
    "y_train = y_train.replace('label', 0 , regex=True)  #把label轉為0  df.replace or series.replace\n",
    "\n",
    "x_test = test[\"text\"]\n",
    "y_test = sample_submission[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/danny/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "x_train :  (4987, 63250)\n",
      "x_test :  (1247, 63250)\n",
      "  (0, 23724)\t1\n",
      "  (0, 32553)\t1\n",
      "  (0, 56606)\t2\n",
      "  (0, 51038)\t1\n",
      "  (0, 38882)\t1\n",
      "  (0, 20124)\t1\n",
      "  (0, 57514)\t1\n",
      "  (0, 23732)\t1\n",
      "  (0, 33973)\t1\n",
      "  (0, 34039)\t2\n",
      "  (0, 7941)\t6\n",
      "  (0, 50550)\t4\n",
      "  (0, 20242)\t1\n",
      "  (0, 282)\t1\n",
      "  (0, 40053)\t1\n",
      "  (0, 9323)\t3\n",
      "  (0, 47443)\t6\n",
      "  (0, 16697)\t3\n",
      "  (0, 39450)\t1\n",
      "  (0, 237)\t1\n",
      "  (0, 628)\t1\n",
      "  (0, 39401)\t1\n",
      "  (0, 57801)\t1\n",
      "  (0, 37305)\t1\n",
      "  (0, 11263)\t1\n",
      "  :\t:\n",
      "  (4986, 3195)\t1\n",
      "  (4986, 3975)\t2\n",
      "  (4986, 44884)\t1\n",
      "  (4986, 41932)\t1\n",
      "  (4986, 44470)\t1\n",
      "  (4986, 309)\t1\n",
      "  (4986, 23373)\t1\n",
      "  (4986, 28347)\t1\n",
      "  (4986, 30641)\t1\n",
      "  (4986, 15952)\t1\n",
      "  (4986, 15511)\t1\n",
      "  (4986, 13528)\t13\n",
      "  (4986, 38691)\t1\n",
      "  (4986, 53261)\t4\n",
      "  (4986, 18087)\t2\n",
      "  (4986, 27625)\t2\n",
      "  (4986, 15950)\t1\n",
      "  (4986, 3585)\t1\n",
      "  (4986, 26424)\t1\n",
      "  (4986, 47155)\t2\n",
      "  (4986, 36324)\t1\n",
      "  (4986, 41181)\t1\n",
      "  (4986, 22336)\t1\n",
      "  (4986, 46457)\t1\n",
      "  (4986, 57425)\t3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#reference: https://www.tutorialspoint.com/python_text_processing/python_remove_stopwords.htm\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words() #dataset包含了各國語言，所以不能只單獨使用english\n",
    "\n",
    "cv = CountVectorizer(stop_words = stopwords_list)   #利用stop_words參數去把stop words去除掉\n",
    "x_train = cv.fit_transform(train[\"text\"])   #vector型態\n",
    "x_test =  cv.transform(test[\"text\"])   #vector型態\n",
    "\n",
    "# fit_transform v.s. transform : https://medium.com/@maggieliao.cm04g/scikit-learn-%E6%95%B8%E6%93%9A%E9%A0%90%E8%99%95%E7%90%86-fit-transform-%E8%88%87transform-%E4%B9%8B%E5%B7%AE%E7%95%B0-3c7cc07c124f\n",
    "\n",
    "print(\"x_train : \", x_train.shape)\n",
    "print(\"x_test : \", x_test.shape)\n",
    "print(x_train)\n",
    "# print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_tfidf 資料型態： <class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 62123)\t0.03621289735920745\n",
      "  (0, 62003)\t0.026467462361343258\n",
      "  (0, 61994)\t0.021996089826837876\n",
      "  (0, 61708)\t0.03503795667476213\n",
      "  (0, 61597)\t0.02578439087892961\n",
      "  (0, 61109)\t0.05229744895417865\n",
      "  (0, 61016)\t0.03618097484983312\n",
      "  (0, 60796)\t0.049898230593484846\n",
      "  (0, 60591)\t0.034029047189863604\n",
      "  (0, 60475)\t0.10405222327417042\n",
      "  (0, 58499)\t0.09886189701446695\n",
      "  (0, 57875)\t0.04911451728421352\n",
      "  (0, 57865)\t0.03511106321055882\n",
      "  (0, 57801)\t0.05304896023374879\n",
      "  (0, 57768)\t0.037037984413813424\n",
      "  (0, 57514)\t0.05185599418611214\n",
      "  (0, 56641)\t0.025601718234430252\n",
      "  (0, 56606)\t0.07551327353665142\n",
      "  (0, 55584)\t0.07961050259117623\n",
      "  (0, 53445)\t0.030043516710702357\n",
      "  (0, 53166)\t0.044974436477612394\n",
      "  (0, 52357)\t0.053596351358158406\n",
      "  (0, 52173)\t0.06890745747175894\n",
      "  (0, 51452)\t0.10405222327417042\n",
      "  (0, 51277)\t0.05298955910801573\n",
      "  :\t:\n",
      "  (4986, 3912)\t0.01616212067265448\n",
      "  (4986, 3910)\t0.016691048618657046\n",
      "  (4986, 3585)\t0.03097872511011741\n",
      "  (4986, 3508)\t0.013708610736537041\n",
      "  (4986, 3475)\t0.059521661005329955\n",
      "  (4986, 3409)\t0.02038125652317271\n",
      "  (4986, 3355)\t0.020267344517700247\n",
      "  (4986, 3195)\t0.03269525115036214\n",
      "  (4986, 3086)\t0.017684289180740647\n",
      "  (4986, 2948)\t0.021624886614841396\n",
      "  (4986, 2896)\t0.025608515247515375\n",
      "  (4986, 2893)\t0.0518312910861111\n",
      "  (4986, 2889)\t0.028286283127941285\n",
      "  (4986, 2774)\t0.022877340386588157\n",
      "  (4986, 2263)\t0.037643087495644253\n",
      "  (4986, 1710)\t0.03051482777330955\n",
      "  (4986, 1567)\t0.016905656605987186\n",
      "  (4986, 1135)\t0.013423964871130978\n",
      "  (4986, 725)\t0.012893214717884464\n",
      "  (4986, 703)\t0.016707176158604377\n",
      "  (4986, 701)\t0.05257354943725208\n",
      "  (4986, 309)\t0.027006584881010126\n",
      "  (4986, 282)\t0.013364857815126434\n",
      "  (4986, 201)\t0.012601572773233243\n",
      "  (4986, 98)\t0.011316816452554022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer    #TF-IDF計算個別term權重\n",
    "tfidf = TfidfTransformer()\n",
    "x_train_tfidf = tfidf.fit_transform(x_train)\n",
    "x_test_tfidf = tfidf.transform(x_test)\n",
    "print(\"x_train_tfidf 資料型態：\", type(x_train_tfidf))\n",
    "# print(x_test_tfidf)\n",
    "print(x_train_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def xgaboost():\n",
    "\n",
    "        import xgboost as xgb\n",
    "\n",
    "        d_train = xgb.DMatrix(x_train_tfidf, y_train)  # load a scipy.sparse array into DMatrix\n",
    "        d_test = xgb.DMatrix(x_test_tfidf, y_test)\n",
    "        print(\"d_train 資料型態：\", type(d_train))\n",
    "\n",
    "        # 建模 referece:https://blog.csdn.net/asialee_bird/article/details/94836962\n",
    "        #\n",
    "        param = {'silent': 0, 'eta': 0.3, 'max_depth': 6, 'objective': 'multi:softmax', 'num_class': 2, 'eval_metric': 'merror'}  #參數表\n",
    "        evallist = [(d_train, 'train'), (d_test, 'test')]\n",
    "        num_round = 100\n",
    "        xgb_model = xgb.train(param, d_train, num_round,evallist)\n",
    "\n",
    "        # 保存訓練模型\n",
    "        # xgb_model.save_model('data/xgb_model')\n",
    "        # xgb_model=xgb.Booster\n",
    "        # (model_file='data/xgb_model') #讀取訓練好的xgboost模型\n",
    "\n",
    "\n",
    "        from sklearn import metrics\n",
    "\n",
    "        y_predict = xgb_model.predict(d_test)  # 模型預測\n",
    "        label_all = ['真新聞','假新聞']\n",
    "        confusion_matrix = metrics.confusion_matrix(y_test, y_predict)\n",
    "        df = pd.DataFrame(confusion_matrix, columns=label_all)\n",
    "        df.index = label_all\n",
    "        print('準確率：', metrics.accuracy_score(y_test, y_predict))\n",
    "        print('confusion_matrix:')\n",
    "        print(df)\n",
    "        print('分類報告:')\n",
    "        print(metrics.classification_report(y_test, y_predict))\n",
    "\n",
    "    def lightgbm(x_test, x_train_tfidf, y_train):\n",
    "        from lightgbm import LGBMClassifier\n",
    "        model = LGBMClassifier()\n",
    "        y_train = y_train.astype('int')\n",
    "        model = model.fit(x_train_tfidf, y_train)\n",
    "\n",
    "        x_test = x_test.astype('float')\n",
    "        y_predicted = model.predict(x_test)\n",
    "\n",
    "\n",
    "        label_all = ['真新聞','假新聞']\n",
    "        confusion_matrix = metrics.confusion_matrix(y_test, y_predicted)\n",
    "        df = pd.DataFrame(confusion_matrix, columns=label_all)\n",
    "        df.index = label_all\n",
    "        print('準確率：', metrics.accuracy_score(y_test, y_predicted))\n",
    "        print('confusion_matrix:')\n",
    "        print(df)\n",
    "        print('分類報告:')\n",
    "        print(metrics.classification_report(y_test, y_predicted))\n",
    "        # for kaggle output:\n",
    "        # submission = pd.DataFrame({\n",
    "        #                     \"label\": y_predicted\n",
    "        #                  })\n",
    "        # submission.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    def GBDT(x_test, x_train_tfidf, y_train):\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "        clf = GradientBoostingClassifier(random_state=0)\n",
    "        y_train = y_train.astype('int')\n",
    "        clf = clf.fit(x_train_tfidf, y_train) \n",
    "        x_test = x_test.astype('float')\n",
    "        y_predicted = clf.predict(x_test)\n",
    "\n",
    "        label_all = ['真新聞','假新聞']\n",
    "        confusion_matrix = metrics.confusion_matrix(y_test, y_predicted)\n",
    "        df = pd.DataFrame(confusion_matrix, columns=label_all)\n",
    "        df.index = label_all\n",
    "        print('準確率：', metrics.accuracy_score(y_test, y_predicted))\n",
    "        print('confusion_matrix:')\n",
    "        print(df)\n",
    "        print('分類報告:')\n",
    "        print(metrics.classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_train 資料型態： <class 'xgboost.core.DMatrix'>\n",
      "[21:57:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.25887\ttest-merror:0.50441\n",
      "[1]\ttrain-merror:0.24063\ttest-merror:0.49559\n",
      "[2]\ttrain-merror:0.23120\ttest-merror:0.49800\n",
      "[3]\ttrain-merror:0.22920\ttest-merror:0.49559\n",
      "[4]\ttrain-merror:0.21777\ttest-merror:0.50120\n",
      "[5]\ttrain-merror:0.21155\ttest-merror:0.50201\n",
      "[6]\ttrain-merror:0.20373\ttest-merror:0.49960\n",
      "[7]\ttrain-merror:0.19290\ttest-merror:0.49880\n",
      "[8]\ttrain-merror:0.18689\ttest-merror:0.49880\n",
      "[9]\ttrain-merror:0.18107\ttest-merror:0.49719\n",
      "[10]\ttrain-merror:0.17686\ttest-merror:0.50281\n",
      "[11]\ttrain-merror:0.16744\ttest-merror:0.50281\n",
      "[12]\ttrain-merror:0.16322\ttest-merror:0.50762\n",
      "[13]\ttrain-merror:0.16182\ttest-merror:0.50521\n",
      "[14]\ttrain-merror:0.15159\ttest-merror:0.50842\n",
      "[15]\ttrain-merror:0.14277\ttest-merror:0.50361\n",
      "[16]\ttrain-merror:0.13696\ttest-merror:0.50441\n",
      "[17]\ttrain-merror:0.13254\ttest-merror:0.50120\n",
      "[18]\ttrain-merror:0.12553\ttest-merror:0.50441\n",
      "[19]\ttrain-merror:0.12212\ttest-merror:0.50521\n",
      "[20]\ttrain-merror:0.12051\ttest-merror:0.50762\n",
      "[21]\ttrain-merror:0.11710\ttest-merror:0.50842\n",
      "[22]\ttrain-merror:0.11450\ttest-merror:0.50842\n",
      "[23]\ttrain-merror:0.11109\ttest-merror:0.51002\n",
      "[24]\ttrain-merror:0.10969\ttest-merror:0.51002\n",
      "[25]\ttrain-merror:0.10587\ttest-merror:0.50842\n",
      "[26]\ttrain-merror:0.10207\ttest-merror:0.50762\n",
      "[27]\ttrain-merror:0.09926\ttest-merror:0.50601\n",
      "[28]\ttrain-merror:0.09785\ttest-merror:0.50040\n",
      "[29]\ttrain-merror:0.09585\ttest-merror:0.50201\n",
      "[30]\ttrain-merror:0.09264\ttest-merror:0.50201\n",
      "[31]\ttrain-merror:0.08723\ttest-merror:0.50762\n",
      "[32]\ttrain-merror:0.08502\ttest-merror:0.50521\n",
      "[33]\ttrain-merror:0.08402\ttest-merror:0.50601\n",
      "[34]\ttrain-merror:0.08161\ttest-merror:0.50441\n",
      "[35]\ttrain-merror:0.07800\ttest-merror:0.50281\n",
      "[36]\ttrain-merror:0.07720\ttest-merror:0.49960\n",
      "[37]\ttrain-merror:0.07640\ttest-merror:0.50281\n",
      "[38]\ttrain-merror:0.07459\ttest-merror:0.50201\n",
      "[39]\ttrain-merror:0.07179\ttest-merror:0.49880\n",
      "[40]\ttrain-merror:0.07139\ttest-merror:0.50281\n",
      "[41]\ttrain-merror:0.06838\ttest-merror:0.50521\n",
      "[42]\ttrain-merror:0.06798\ttest-merror:0.50682\n",
      "[43]\ttrain-merror:0.06657\ttest-merror:0.50682\n",
      "[44]\ttrain-merror:0.06477\ttest-merror:0.50521\n",
      "[45]\ttrain-merror:0.06337\ttest-merror:0.50521\n",
      "[46]\ttrain-merror:0.06296\ttest-merror:0.50601\n",
      "[47]\ttrain-merror:0.06296\ttest-merror:0.50361\n",
      "[48]\ttrain-merror:0.06216\ttest-merror:0.50040\n",
      "[49]\ttrain-merror:0.05976\ttest-merror:0.49719\n",
      "[50]\ttrain-merror:0.05815\ttest-merror:0.50040\n",
      "[51]\ttrain-merror:0.05695\ttest-merror:0.50201\n",
      "[52]\ttrain-merror:0.05474\ttest-merror:0.50281\n",
      "[53]\ttrain-merror:0.05354\ttest-merror:0.50120\n",
      "[54]\ttrain-merror:0.05093\ttest-merror:0.50361\n",
      "[55]\ttrain-merror:0.04933\ttest-merror:0.50441\n",
      "[56]\ttrain-merror:0.04873\ttest-merror:0.50521\n",
      "[57]\ttrain-merror:0.04933\ttest-merror:0.50601\n",
      "[58]\ttrain-merror:0.04732\ttest-merror:0.50842\n",
      "[59]\ttrain-merror:0.04712\ttest-merror:0.50922\n",
      "[60]\ttrain-merror:0.04612\ttest-merror:0.50682\n",
      "[61]\ttrain-merror:0.04391\ttest-merror:0.50682\n",
      "[62]\ttrain-merror:0.04171\ttest-merror:0.50842\n",
      "[63]\ttrain-merror:0.04071\ttest-merror:0.50922\n",
      "[64]\ttrain-merror:0.03870\ttest-merror:0.50842\n",
      "[65]\ttrain-merror:0.03730\ttest-merror:0.50361\n",
      "[66]\ttrain-merror:0.03649\ttest-merror:0.50281\n",
      "[67]\ttrain-merror:0.03589\ttest-merror:0.50361\n",
      "[68]\ttrain-merror:0.03489\ttest-merror:0.50441\n",
      "[69]\ttrain-merror:0.03409\ttest-merror:0.50521\n",
      "[70]\ttrain-merror:0.03389\ttest-merror:0.50361\n",
      "[71]\ttrain-merror:0.03208\ttest-merror:0.50281\n",
      "[72]\ttrain-merror:0.03208\ttest-merror:0.50441\n",
      "[73]\ttrain-merror:0.03068\ttest-merror:0.50682\n",
      "[74]\ttrain-merror:0.03008\ttest-merror:0.50842\n",
      "[75]\ttrain-merror:0.02968\ttest-merror:0.51163\n",
      "[76]\ttrain-merror:0.02908\ttest-merror:0.51323\n",
      "[77]\ttrain-merror:0.02928\ttest-merror:0.51323\n",
      "[78]\ttrain-merror:0.02948\ttest-merror:0.51403\n",
      "[79]\ttrain-merror:0.02908\ttest-merror:0.51323\n",
      "[80]\ttrain-merror:0.02807\ttest-merror:0.51002\n",
      "[81]\ttrain-merror:0.02827\ttest-merror:0.51243\n",
      "[82]\ttrain-merror:0.02787\ttest-merror:0.51243\n",
      "[83]\ttrain-merror:0.02667\ttest-merror:0.51323\n",
      "[84]\ttrain-merror:0.02647\ttest-merror:0.51323\n",
      "[85]\ttrain-merror:0.02567\ttest-merror:0.51243\n",
      "[86]\ttrain-merror:0.02466\ttest-merror:0.51243\n",
      "[87]\ttrain-merror:0.02487\ttest-merror:0.50922\n",
      "[88]\ttrain-merror:0.02446\ttest-merror:0.50922\n",
      "[89]\ttrain-merror:0.02386\ttest-merror:0.51002\n",
      "[90]\ttrain-merror:0.02346\ttest-merror:0.50922\n",
      "[91]\ttrain-merror:0.02326\ttest-merror:0.51163\n",
      "[92]\ttrain-merror:0.02306\ttest-merror:0.50922\n",
      "[93]\ttrain-merror:0.02246\ttest-merror:0.51002\n",
      "[94]\ttrain-merror:0.02246\ttest-merror:0.51002\n",
      "[95]\ttrain-merror:0.02206\ttest-merror:0.51002\n",
      "[96]\ttrain-merror:0.02166\ttest-merror:0.51002\n",
      "[97]\ttrain-merror:0.02146\ttest-merror:0.51323\n",
      "[98]\ttrain-merror:0.02106\ttest-merror:0.51323\n",
      "[99]\ttrain-merror:0.02085\ttest-merror:0.51243\n",
      "準確率： 0.48757016840417\n",
      "confusion_matrix:\n",
      "     真新聞  假新聞\n",
      "真新聞  410  220\n",
      "假新聞  419  198\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.65      0.56       630\n",
      "           1       0.47      0.32      0.38       617\n",
      "\n",
      "    accuracy                           0.49      1247\n",
      "   macro avg       0.48      0.49      0.47      1247\n",
      "weighted avg       0.48      0.49      0.47      1247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgaboost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "準確率： 0.49318364073777066\n",
      "confusion_matrix:\n",
      "     真新聞  假新聞\n",
      "真新聞  381  249\n",
      "假新聞  383  234\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.55       630\n",
      "           1       0.48      0.38      0.43       617\n",
      "\n",
      "    accuracy                           0.49      1247\n",
      "   macro avg       0.49      0.49      0.49      1247\n",
      "weighted avg       0.49      0.49      0.49      1247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lightgbm(x_test, x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "準確率： 0.5140336808340016\n",
      "confusion_matrix:\n",
      "     真新聞  假新聞\n",
      "真新聞  443  187\n",
      "假新聞  419  198\n",
      "分類報告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.70      0.59       630\n",
      "           1       0.51      0.32      0.40       617\n",
      "\n",
      "    accuracy                           0.51      1247\n",
      "   macro avg       0.51      0.51      0.49      1247\n",
      "weighted avg       0.51      0.51      0.50      1247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GBDT(x_test, x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
